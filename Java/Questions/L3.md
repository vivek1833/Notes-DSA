# ✅ Java Interview Questions – Level 3

## 1. How does the JVM work internally? (Class Loader, GC, memory areas)

**Explanation:** JVM executes Java bytecode and provides an abstraction over the OS and CPU. Key components:

- **Class Loader Subsystem**: Loads `.class` files into memory. Follows a _delegation model_ (Bootstrap → Extension → System → Application/custom). Loading stages: _Loading, Linking (verification, preparation, resolution), Initialization_.
- **Runtime Data Areas**:

  - **Method Area (PermGen / Metaspace)**: Stores class metadata, static variables, constant pool. In modern JVMs (Java 8+), class metadata is stored in _Metaspace_ (native memory) instead of PermGen.
  - **Heap**: All objects (instance data) are allocated here. Divided into generations: _Young (Eden + Survivor)_ and _Old/Tenured_. Most GC activity happens here.
  - **Stack**: Each thread gets its own stack containing frames for method calls (local variables, operand stack, etc.). Primitive values and object references live here.
  - **Program Counter (PC) Register**: Points to the current JVM instruction.
  - **Native Method Stacks**: For native (JNI) calls.

- **Garbage Collector (GC)**: Reclaims unused objects. Generational collectors (like G1, Parallel, CMS historically) assume most objects die young. GC algorithms: Mark-and-Sweep, Mark-Compact, Copying, Generational, Concurrent Mark Sweep, Garbage-First (G1), ZGC, Shenandoah.

**Key interview points:** Class loader delegation, difference between Metaspace and PermGen, generational GC, stop-the-world pauses vs concurrent collectors, tuning with JVM flags (`-Xmx`, `-Xms`, `-XX:+UseG1GC`, `-XX:MaxMetaspaceSize`).

---

## 2. What are different types of class loaders in Java?

**Explanation:** The common class loaders are:

- **Bootstrap ClassLoader** (native, loads JDK core classes from `rt.jar` or modular runtime). It has no parent in Java terms.
- **Extension (Platform) ClassLoader** (loads platform libraries).
- **System (Application) ClassLoader** (loads classes from application classpath).
- **Custom ClassLoaders**: You can extend `ClassLoader` to implement isolation, dynamic loading, hot-reloading, or plugin systems.

**Key interview points:** Delegation model — class loader first delegates to its parent; visibility rules; how `Thread.currentThread().getContextClassLoader()` is used; class unloading constraints (classes can be unloaded only when the ClassLoader itself is garbage collected).

---

## 3. What are phantom references in Java?

**Explanation:** Java provides `Reference` classes: `SoftReference`, `WeakReference`, and `PhantomReference` (in `java.lang.ref`).

- **SoftReference**: Used for caches; objects are reclaimed only when JVM needs memory.
- **WeakReference**: Collected in the next GC if no strong references exist.
- **PhantomReference**: Always returns `null` from `get()`. It’s enqueued **after** the object has been finalized but **before** the memory is reclaimed. Used to perform post-mortem cleanup and determine exactly when an object is phantom-reachable. `PhantomReference` requires a `ReferenceQueue` to learn when the object is collected.

**Example use-case:** Cleaner implementations, custom memory management with native resources, avoiding resurrection in finalizers.

**Code sketch:**

```java
ReferenceQueue<MyObject> queue = new ReferenceQueue<>();
PhantomReference<MyObject> pr = new PhantomReference<>(new MyObject(), queue);
// Poll the queue to know when MyObject is enqueued (eligible for reclamation)
```

---

## 4. How does Java handle memory leaks despite having garbage collector?

**Explanation:** GC reclaims only objects that are unreachable from GC roots. Memory "leaks" happen when references are unintentionally retained, preventing GC.

**Common causes:**

- Static collections that keep growing (`static Map` or `List`).
- Listeners or callbacks not removed.
- ThreadLocal objects whose values are not cleared — especially when thread pools are used.
- Cache misuse without eviction policy.
- Large object graphs or native memory leaks (via JNI or direct `ByteBuffer` allocations).

**How to detect:** heap dumps, profilers (VisualVM, YourKit, JProfiler), `jmap -dump`, `jstat`, GC logs.

**Mitigation:** use weak/soft references for caches, remove listeners, clear ThreadLocals, size limits and eviction (LRU), use connection pooling and close resources.

---

## 5. How do you analyze heap dumps in Java?

**Explanation:** Heap dumps capture a snapshot of the heap memory and can be analyzed to find memory leaks and object-retention paths.

**Steps:**

1. Generate dump: `jmap -dump:live,format=b,file=heap.hprof <pid>` or via `-XX:+HeapDumpOnOutOfMemoryError`.
2. Open with tools: **Eclipse MAT (Memory Analyzer Tool)**, VisualVM, YourKit, JProfiler.
3. Look for suspects:
   - Dominator tree (which objects retain most memory).
   - Top consumers by instance count and retained size.
   - Paths to GC roots to find why objects are retained.
4. Use MAT queries (OQL) and the Leak Suspects report.

**Key tips:** compare multiple heap dumps over time, filter known large caches, inspect retained sizes rather than shallow sizes.

---

## 6. What is Executor framework in Java?

**Explanation:** The Executor framework (in `java.util.concurrent`) decouples task submission from execution. Core interfaces/classes:

- `Executor` — single `execute(Runnable)` method.
- `ExecutorService` — extends Executor with lifecycle (submit, shutdown, awaitTermination) and futures.
- `ScheduledExecutorService` — supports scheduled tasks.
- `ThreadPoolExecutor` — configurable pool implementation.
- `Executors` — factory utility class (`newFixedThreadPool`, `newCachedThreadPool`, `newSingleThreadExecutor`, `newScheduledThreadPool`).

**Key interview points:** task queuing, rejection policies, thread factories, bounded vs unbounded queues, proper shutdown.

**Sample:**

```java
ExecutorService ex = Executors.newFixedThreadPool(4);
ex.submit(() -> System.out.println("task"));
ex.shutdown();
```

---

## 7. What is a Future in Java?

**Explanation:** `Future<V>` represents result of an asynchronous computation. You can `get()` the result (blocking), `cancel()` it, or check `isDone()`.

**Limitations:** `Future` cannot be composed easily; `get()` blocks and provides no direct callback. `CompletableFuture` (Java 8) addresses these with functional callbacks, chaining, and non-blocking composition.

**Sample:**

```java
Future<Integer> f = ex.submit(() -> {
    Thread.sleep(500);
    return 42;
});
int result = f.get(); // blocks
```

---

## 8. What is a Thread pool & why should we use it?

**Explanation:** A thread pool reuses a fixed number of threads to execute tasks. Benefits:

- **Resource control:** Limits concurrent threads (avoids too many threads/spawning overhead).
- **Reduced latency:** Reuse threads instead of creating/destroying them often.
- **Throughput:** Efficient task scheduling and queueing.

**Considerations:** choose thread count based on CPU-bound vs I/O-bound tasks. For CPU-bound tasks, threads ~ number of cores. For I/O-bound tasks, higher thread count may help.

---

## 9. Difference between `synchronized` and `ReentrantLock`?

**Explanation & differences:**

- `synchronized` is a language construct; `ReentrantLock` is a class with advanced features.
- **Reentrancy:** both are reentrant.
- **TryLock & timed waits:** `ReentrantLock` supports `tryLock()` and `tryLock(timeout, unit)` while `synchronized` cannot.
- **Interruptible lock acquisition:** `lockInterruptibly()` allows thread to be interrupted while waiting — `synchronized` does not.
- **Fairness:** `ReentrantLock` can be created as fair; `synchronized` has no fairness guarantee.
- **Condition objects:** `ReentrantLock` supports multiple `Condition`s for more flexible waiting/notification; `synchronized` uses a single monitor and `wait()/notify()/notifyAll()`.

**Code sample (tryLock):**

```java
ReentrantLock lock = new ReentrantLock();
if(lock.tryLock()){
    try{ /* critical section */ } finally { lock.unlock(); }
}
```

---

## 10. Difference between `volatile` and `synchronized`?

**Explanation:**

- `volatile` ensures **visibility** of writes to variables across threads and prevents reordering of reads/writes to that variable (it provides a lightweight memory barrier). It does **not** provide atomicity for compound operations.
- `synchronized` provides both **mutual exclusion** (only one thread can execute the critical section) and **visibility** (entering/exiting a monitor establishes happens-before relationships).

**Example where volatile is insufficient:**

```java
volatile int counter = 0;
// counter++ is NOT atomic (read-modify-write), so race conditions possible
```

---

## 11. Difference between thread safety and atomicity?

**Explanation:**

- **Atomicity**: an operation is atomic if it appears to happen as a single indivisible step (e.g., `AtomicInteger.incrementAndGet()`).
- **Thread safety**: an API or code is thread-safe if it functions correctly when accessed from multiple threads concurrently (often via synchronization, immutability, or concurrent data structures).

Atomic operations are one building block to achieve thread safety, but thread safety often requires coordination of multiple operations.

---

## 12. Difference between busy-waiting vs blocking vs non-blocking calls?

**Explanation:**

- **Busy-waiting**: repeatedly checking a condition in a loop (wastes CPU cycles). Example: `while(!flag) {}`.
- **Blocking**: thread yields CPU and is suspended by OS/JVM until condition/event occurs (efficient). Example: `Object.wait()`, `BlockingQueue.take()`.
- **Non-blocking**: algorithms that make progress without blocking threads, usually using atomic primitives (`compareAndSet`). Can be lock-free or wait-free.

**Interview note:** prefer blocking primitives for simpler design; non-blocking for high-performance, low-latency systems.

---

## 13. How does `CompletableFuture` work internally?

**Explanation:**
`CompletableFuture` implements `Future` and `CompletionStage` and is backed by a ForkJoinPool (`ForkJoinPool.commonPool()`) for async tasks by default. Key ideas:

- **Non-blocking composition**: `thenApply`, `thenCompose`, `thenAccept` return new stages and schedule callbacks when previous stage completes.
- **Execution**: `supplyAsync` or `runAsync` submit tasks to an `Executor`. Dependent stages get enqueued and executed when the dependency completes; internal data structures manage completion state and dependent actions.

**Important internals:** uses `Unsafe` and CAS operations to update completion state, and a list of dependent actions; uses `ForkJoinTask` for parallelism.

**Example:**

```java
CompletableFuture.supplyAsync(() -> fetch())
    .thenApply(this::transform)
    .thenAccept(System.out::println);
```

---

## 14. What is Producer-Consumer pattern? Implement with `BlockingQueue`.

**Explanation:**
Producer-Consumer decouples producers (create tasks/data) from consumers (process tasks/data) via a thread-safe queue. `BlockingQueue` implementations handle synchronization, blocking producers when full and consumers when empty.

**Code example:**

```java
import java.util.concurrent.*;

BlockingQueue<Integer> q = new ArrayBlockingQueue<>(10);
ExecutorService ex = Executors.newFixedThreadPool(4);

Runnable producer = () -> {
  try {
    for(int i=0;i<100;i++){
      q.put(i);
    }
    q.put(-1); // poison pill
  } catch (InterruptedException e){ Thread.currentThread().interrupt(); }
};

Runnable consumer = () -> {
  try {
    while(true){
      int v = q.take();
      if(v == -1) break;
      // process v
    }
  } catch(InterruptedException e){ Thread.currentThread().interrupt(); }
};

ex.submit(producer);
ex.submit(consumer);
ex.shutdown();
```

---

## 15. How does Java Stream work internally? (parallel vs sequential)

**Explanation:**

- **Sequential streams** operate on a pipeline of intermediate operations (map/filter), which are _lazy_ — nothing runs until a terminal operation (collect, forEach) is invoked. The stream builds a pipeline of `Sink` objects internally and processes elements one-by-one.
- **Parallel streams** split the data source into `Spliterator` chunks and process chunks in parallel (using `ForkJoinPool.commonPool()` by default). Results are combined using `Collector`’s combiner. Performance depends on the data source (ArrayList/primitive arrays are good), stateless operations, and side-effect-free functions.

**Important considerations:**

- Avoid shared mutable state in lambdas.
- Prefer `collect()` with thread-safe collectors or use `Collectors.toList()` which handles parallel accumulation.
- Use `parallelStream()` judiciously — not always faster (small datasets, I/O-bound operations may be slower).

---

## 16. How does `Semaphore` work? Real life examples?

**Explanation:**
`Semaphore` (in `java.util.concurrent`) maintains a set of permits. Threads `acquire()` permits (blocking if none available) and `release()` them. Useful for limiting concurrent access to a resource.

**Real-life examples:**

- Limiting database connections to a max number.
- Controlling access to a pool of printers.

**Code sample:**

```java
Semaphore s = new Semaphore(3); // 3 permits
s.acquire();
try { /* access resource */ } finally { s.release(); }
```

---

## 17. What is a BlockingQueue? Its usage and types?

**Explanation:**
`BlockingQueue` is a concurrent queue supporting operations that wait for the queue to become non-empty when retrieving, and wait for space to become available when storing.

**Common implementations:**

- `ArrayBlockingQueue` — bounded, backed by array, optionally fair.
- `LinkedBlockingQueue` — optionally bounded, linked nodes.
- `PriorityBlockingQueue` — priority ordering.
- `SynchronousQueue` — handoff; no internal capacity.
- `LinkedTransferQueue` — unbounded, advanced transfer features.

**Usage:** thread pools, producer-consumer patterns, work queues.

---

## 18. How does Spring manage Bean lifecycle? What are the hooks?

**Explanation:**
Spring creates and manages beans in the ApplicationContext. Lifecycle phases:

1. Instantiate bean.
2. Populate properties (dependency injection).
3. `BeanNameAware`, `BeanFactoryAware`, `ApplicationContextAware` callbacks.
4. `BeanPostProcessor` (pre-initialization hooks).
5. `@PostConstruct` or `InitializingBean.afterPropertiesSet()`.
6. `BeanPostProcessor` (post-initialization hooks).
7. Bean ready to use.
8. Shutdown: `@PreDestroy` or `DisposableBean.destroy()`.

**Code hooks:**

```java
@Component
public class MyBean implements InitializingBean, DisposableBean {
  @Override public void afterPropertiesSet(){ /* init */ }
  @Override public void destroy(){ /* cleanup */ }

  @PostConstruct public void init(){ }
  @PreDestroy public void cleanup(){ }
}
```

---

## 19. What is the default scope of a Bean in Spring?

**Answer:** `singleton` (one shared instance per Spring `ApplicationContext`). For web apps, `request`, `session`, and `application` scopes exist.

---

## 20. How does optimistic locking work in JPA? `@Version` annotation?

**Explanation:**
Optimistic locking assumes conflicts are rare and checks for conflicts at commit time. JPA supports it via a version column.

**How it works:**

- Entity has `@Version` field (int, long, or timestamp).
- On read, the version is loaded. On update, the `WHERE` clause includes the version. If no row is updated (because version changed), JPA throws `OptimisticLockException`.

**Example:**

```java
@Entity
public class Account {
  @Id private Long id;
  @Version private Long version;
  private BigDecimal balance;
}
```

**Usage:** safe concurrent updates without pessimistic locking.

---

## 21. How do you handle Pagination and Sorting in Spring Data JPA?

**Explanation & sample:**
Spring Data provides `Pageable` and `Sort`.

```java
Pageable p = PageRequest.of(page, size, Sort.by("name").ascending());
Page<User> pageUser = userRepository.findAll(p);
List<User> users = pageUser.getContent();
long total = pageUser.getTotalElements();
```

**Controller params:** accept `page`, `size`, `sort` and map to `Pageable` (Spring can auto-bind with `@PageableDefault`).

---

## 22. What is Connection Pooling?

**Explanation:**
Connection pooling reuses database connections, avoiding the overhead of creating/closing connections per request. Pools (HikariCP, Tomcat JDBC, DBCP) manage sizing, idle timeouts, max lifetime, and validation.

**Key settings:** `maxPoolSize`, `connectionTimeout`, `idleTimeout`, `maxLifetime`, validation query.

---

## 23. What is stateless session? How does JWT help?

**Explanation:**

- **Stateless session**: server does not store session state; each request contains all needed authentication data.
- **JWT (JSON Web Token)**: a compact, signed token that carries claims; server validates signature and derives identity without server-side session storage.

**Security notes:** keep tokens short-lived, use refresh tokens, secure storage on client, and use HTTPS. Consider revocation strategies (token blacklist, short expiry).

---

## 24. How do you implement 2FA?

**Explanation:**
Common 2FA approaches:

- **TOTP (Time-based One-Time Password)**: Google Authenticator style. Server stores secret per user; both client and server compute tokens based on time slices.
- **SMS / Email OTP**: send code to user (less secure due to SIM swap, interception).
- **Hardware tokens / U2F**: secure physical keys.

**Flow (TOTP):**

1. Generate secret, show QR to user.
2. User scans with authenticator app.
3. On login, server asks for TOTP code and verifies.

**Library:** `Google Authenticator` implementations or `com.warrenstrange:googleauth`.

---

## 25. How do you secure micro-services connection?

**Explanation:**

- Use **mTLS** (mutual TLS) for service-to-service authentication.
- Use **OAuth2 / JWT** tokens issued by an identity provider; services validate tokens.
- Network-level controls: service mesh (Istio, Linkerd) can provide mTLS, observability, and traffic routing.
- Secrets management: Vault or cloud KMS for storing credentials.
- Rate limiting, circuit breakers, and TLS encryption in transit.

---

## 26. How to implement OAuth2 authentication in Java Spring Boot?

**Explanation (high-level):**

- Use **Spring Security** and `spring-security-oauth2-client` for Authorization Code flow.
- Configure OAuth2 clients (client-id/secret, callback URL) in `application.yml`.
- Use `@EnableWebSecurity` and configure security filters or rely on auto-configuration.

**Minimal config (application.yml):**

```yaml
spring:
  security:
    oauth2:
      client:
        registration:
          google:
            client-id: <id>
            client-secret: <secret>
            scope: openid,profile,email
```

**Notes:** for resource servers validate JWT tokens with `spring-boot-starter-oauth2-resource-server` and configure issuer/jwk set URI.

---

## 27. What are the core components of Apache Kafka?

**Explanation:**

- **Broker**: Kafka server storing topics and partitions.
- **Topic**: logical stream of messages.
- **Partition**: ordered, immutable sequence of messages within a topic.
- **Producer**: publishes messages to topics.
- **Consumer**: reads messages from topics.
- **Zookeeper / Kafka Controller**: older Kafka versions use ZooKeeper for metadata; newer KRaft mode removes ZooKeeper.
- **Replication**: partitions are replicated across brokers for durability.

---

## 28. What are Consumer Groups? How does rebalancing work?

**Explanation:**

- **Consumer group**: a set of consumers with same group id. Each partition is consumed by at most one consumer within a group — provides horizontal scaling.
- **Rebalancing**: when consumers join or leave, Kafka reassigns partitions among consumers. During rebalance, consumption pauses; consumers commit offsets and resume after assignment.

**Notes:** minimize unnecessary rebalances (sticky assignment, long-lived consumers) and use cooperative rebalancing to reduce disruptions.

---

## 29. How do you ensure message ordering in Kafka?

**Explanation:**
Ordering is guaranteed **within a partition**. To preserve order for a key, produce messages with the same partitioning key so they map to the same partition. Avoid parallel consumers for the same partition if strict ordering is required.

**Tradeoffs:** throughput vs ordering (more partitions => more parallelism but ordering across partitions not guaranteed).

---

## 30. What is a Partition in Kafka? How does it work?

**Explanation:**
A partition is an ordered, immutable sequence of records. Each partition is assigned to a single leader broker (and replicated to followers). Producers write to leaders; consumers read from leaders. Partitions enable Kafka's scalability and parallelism: topic throughput increases with more partitions but increases coordination cost (and consumer ordering considerations).

### _Key point_
- offsets are per-partition, replication ensures durability and fault-tolerance, leader election happens during failures.

## 31. Practical conflict scenario (high-value)

### **Example:**

Service A calls Service B and Service C.

```json
A.m() [@Transactional]
   ↓
B.op()  // fails
   ↓
C.op()  // should this run?
```

Behavior:

* If A.m() is `REQUIRED` (default), failure in B rolls back whole tx → C never executes.
* If B.op() is declared `REQUIRES_NEW`, then:

  * B’s failure rolls back only B
  * A’s main tx continues
  * C.op() executes normally
---

## **32. Execution flow — what really happens when a transaction starts**

Internal call chain:

1. Proxy intercepts method call
2. TransactionInterceptor checks metadata
3. PlatformTransactionManager creates or joins transaction
4. Binds transaction to thread via ThreadLocal
5. Executes target method
6. On exit:
  * Commit if no rollback rules matched
  * Rollback if exception + rule matches
---

## **33. Transaction propagation and isolation levels**

_Isolation_ = **how much of other people’s in-progress database work you are allowed to see** while your transaction is running.

_Propagation_ = **what your method should do with transactions that already exist** (use it, start a new one, or create a sub-transaction).

Propagation types:

* **REQUIRED** joins caller or creates a new transaction.
* **REQUIRES_NEW** suspends caller and always starts a new transaction.
* **NESTED** creates a savepoint inside caller’s transaction.

Isolation levels:

* **READ_UNCOMMITTED** allows all anomalies.
* **READ_COMMITTED** disallows dirty reads.
* **REPEATABLE_READ** disallows dirty and non-repeatable reads.
* **SERIALIZABLE** disallows all anomalies.
